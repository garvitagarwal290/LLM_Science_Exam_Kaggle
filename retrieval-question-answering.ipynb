{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":54662,"databundleVersionId":6169864,"sourceType":"competition"},{"sourceId":6264602,"sourceType":"datasetVersion","datasetId":3524961},{"sourceId":8074011,"sourceType":"datasetVersion","datasetId":4764536},{"sourceId":8208062,"sourceType":"datasetVersion","datasetId":4778447}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft\n!pip install datasets==2.15\n!pip install faiss-gpu # Use faiss-gpu if on GPU machine (faster)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport pandas as pd\nfrom datasets import load_dataset, Dataset, load_from_disk\nfrom pathlib import Path\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForMultipleChoice, BertForMultipleChoice, TrainingArguments, Trainer, AutoModelForSequenceClassification\nfrom transformers import pipeline\n\nfrom typing import Optional, Union\nfrom dataclasses import dataclass\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nimport peft\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndevice = get_default_device()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\nret_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nret_model = AutoModel.from_pretrained(model_ckpt)\nret_model.to(device).eval()\n\n# Getting the final embedding from the model\ndef cls_pooling(model_output):\n    return model_output.last_hidden_state[:, 0]\n\ndef get_ret_embeddings(text_list):\n    encoded_input = ret_tokenizer(\n        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n    )\n    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n    model_output = ret_model(**encoded_input)\n    return cls_pooling(model_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ret_embeddings_dataset = load_from_disk('/kaggle/input/retrieval-wiki-embeddings')\n\nret_embeddings_dataset.add_faiss_index(column=\"embeddings\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(r'retrieval-embeddings/data-00001-of-00002.arrow')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reader_model = BertForMultipleChoice.from_pretrained(\"google-bert/bert-base-uncased\")\n# reader_tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n\ndeberta_v3 = 'microsoft/deberta-v3-base'\npeft_adapter = '/kaggle/input/science-comp-trained-model'\nreader_model = AutoModelForMultipleChoice.from_pretrained(deberta_v3)\nreader_model.load_adapter(peft_adapter)\n\nreader_tokenizer = AutoTokenizer.from_pretrained(peft_adapter)#, model_max_length=512)\n\nreader_model.to(device).eval()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(examples):\n\n    first_sentences = [[f\"\"\"### CONTEXT: {examples['context'][i]} \"\"\"] * 5 for i in range(len(examples['context']))]\n    second_sentences = [[f\"\"\"### QUESTION: {examples['questions'][i]} ### OPTION: {examples[option][i]}\"\"\" for option in 'ABCDE'] for i in range(len(examples['A']))]\n\n    first_sentences = sum(first_sentences, [])\n    second_sentences = sum(second_sentences, [])\n    \n    tokenized_examples = reader_tokenizer(first_sentences, second_sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n    tokenized_examples = {k: [v[i : i + 5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}\n    tokenized_examples['labels'] = [option_to_index[examples['answer'][i]] for i in range(len(examples['answer']))]\n    \n    return tokenized_examples\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch\n    \n\n    \ntest_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rerank_tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\nrerank_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\nrerank_model.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_best_context(question):\n    question_embedding = get_ret_embeddings([question]).cpu().detach().numpy()\n\n    scores, samples = ret_embeddings_dataset.get_nearest_examples(\n        \"embeddings\", question_embedding, k=10)\n\n    pairs = [(question, text) for text in samples['text']]\n    with torch.no_grad():\n        inputs = rerank_tokenizer(pairs, padding=True, \n                                  truncation=True, \n                                  return_tensors='pt')#, max_length=512)\n        scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()\n\n    samples_df = pd.DataFrame.from_dict(samples)\n    samples_df[\"scores\"] = scores\n    samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n    \n    return samples_df['text'].values[0]\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batchsize = 10\nnumbatches = len(test_df['prompt'])//batchsize\npredictions = []\n\nfor j in range(numbatches):\n    print(j+1)\n    best_contexts = []\n    for i in range(batchsize):\n        question = test_df['prompt'][j*batchsize+i]\n        best_context = get_best_context(question)\n        best_contexts.append(best_context)\n        \n    data = {'id': test_df['id'][j*batchsize: (j+1)*batchsize], 'questions': test_df['prompt'][j*batchsize: (j+1)*batchsize], 'context': best_contexts, 'A': test_df['A'][j*batchsize: (j+1)*batchsize], 'B': test_df['B'][j*batchsize: (j+1)*batchsize],\n            'C': test_df['C'][j*batchsize: (j+1)*batchsize], 'D': test_df['D'][j*batchsize: (j+1)*batchsize], 'E': test_df['E'][j*batchsize: (j+1)*batchsize], \n            'answer': test_df['answer'][j*batchsize: (j+1)*batchsize]}\n \n    df = pd.DataFrame(data)\n\n    tokenized_test = Dataset.from_pandas(df.drop(columns=['id'])).map(preprocess, remove_columns=['questions', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'], batched=True)\n    tokenized_test = tokenized_test.with_format(\"torch\")\n    \n    outputs = reader_model(**{feature: tokenized_test[feature].to(device) for feature in tokenized_test.features})\n    pred_answers = outputs['logits']\n    \n    predictions_as_ids = torch.argsort(-pred_answers, 1)[:,:3]\n    predictions_as_options = np.array(list('ABCDE'))[predictions_as_ids.cpu()]\n    predictions_as_string =  [' '.join(row) for row in predictions_as_options]\n    predictions += predictions_as_string","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = {'id': list(np.arange(len(predictions))), 'prediction': predictions}\nsubmissiondf = pd.DataFrame(submission)\n\nsubmissiondf['answer'] = test_df['answer']\nsubmissiondf.to_csv('/kaggle/working/submission.csv', index=False)\n\n# pd.read_csv('/kaggle/working/submission.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}