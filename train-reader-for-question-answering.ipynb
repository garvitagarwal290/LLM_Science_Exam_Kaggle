{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6387652,"sourceType":"datasetVersion","datasetId":3681660},{"sourceId":8208062,"sourceType":"datasetVersion","datasetId":4778447}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install peft\n!pip install datasets\n!pip install evaluate","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel, BertForMultipleChoice\nimport evaluate\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['WANDB_DISABLED'] = 'true'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndevice = get_default_device()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"deberta = 'microsoft/deberta-v3-base'\nlongformer = 'allenai/longformer-base-4096'\n\n# original_model = BertForMultipleChoice.from_pretrained(\"google-bert/bert-base-uncased\")\n# tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n# original_model = AutoModelForMultipleChoice.from_pretrained(deberta)\n# tokenizer = AutoTokenizer.from_pretrained(deberta, model_max_length=512)\noriginal_model = AutoModelForMultipleChoice.from_pretrained(longformer)\ntokenizer = AutoTokenizer.from_pretrained(longformer, model_max_length=768)\n\noriginal_model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(examples):\n\n    first_sentences = [[f\"\"\"### CONTEXT: {examples['context'][i]} \"\"\"] * 5 for i in range(len(examples['prompt']))]\n    second_sentences = [[f\"\"\"### QUESTION: {examples['prompt'][i]} ### OPTION: {examples[option][i]}\"\"\" for option in 'ABCDE'] for i in range(len(examples['A']))]\n\n    first_sentences = sum(first_sentences, [])\n    second_sentences = sum(second_sentences, [])\n    \n    tokenized_examples = tokenizer(first_sentences, second_sentences, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n    tokenized_examples = {k: [v[i : i + 5] for i in range(0, len(v), 5)] for k, v in tokenized_examples.items()}\n    tokenized_examples['labels'] = [option_to_index[examples['answer'][i]] for i in range(len(examples['answer']))]\n    \n    return tokenized_examples\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch\n    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/llm-science-exam-dataset-w-context-extended/15k_gpt3.5-turbo.csv')\ntrain_df.dropna(inplace=True)\n    \ndataset = Dataset.from_pandas(train_df.iloc[:]).drop(columns=['id'])\ntrain_test_dataset = dataset.train_test_split(test_size=0.1)\n\ntokenized_dataset = train_test_dataset.map(preprocess, remove_columns=['context', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer'], batched=True, batch_size=500)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n\nprint(print_number_of_trainable_model_parameters(original_model))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(\n    r=8, # Rank\n    lora_alpha=8,\n    target_modules=[\"query\", \"value\"],\n#     target_modules=[\"query_proj\", \"value_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_model = get_peft_model(original_model, \n                            lora_config)\nprint(print_number_of_trainable_model_parameters(peft_model))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_training_args = TrainingArguments(\n    per_device_train_batch_size=1,\n#     gradient_accumulation_steps=2,\n    learning_rate=1e-4,\n    num_train_epochs=8,\n    logging_strategy=\"epoch\",\n    evaluation_strategy=\"epoch\",\n    output_dir='.',\n    label_names = [\"labels\"],\n    fp16=True,\n#     gradient_checkpointing=True\n)\n    \npeft_trainer = Trainer(\n    model=peft_model,\n    args=peft_training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    compute_metrics=compute_metrics,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['test']\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntry longformer with 768 max length and all data\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"peft_trainer.train()\n\npeft_model_path=\"./mcq_model\"\n\npeft_trainer.model.save_pretrained(peft_model_path)\ntokenizer.save_pretrained(peft_model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('training_log.json', 'w') as fp:\n    json.dump(peft_trainer.state.log_history, fp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(r'output.zip')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
